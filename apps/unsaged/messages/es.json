{
  "advancedSettings": "Advanced settings",
  "cancel": "Cancelar",
  "chat": {
    "creative": "Creativo",
    "enterMessage": "Escriba un mensaje",
    "error": "Lo sentimos, hubo un error",
    "maxTokens": "Número máximo de tokens",
    "maxTokensDescription": "El número máximo de tokens que se van a generar. Cuanto mayor sea el número, más tiempo tardará la IA en generar una respuesta.",
    "messageLimit": "El límite de mensajes es de {{maxLength}} caracteres. Has introducido {{valueLength}} caracteres.",
    "neutral": "Neutro",
    "newConversation": "Nueva conversación",
    "newFolder": "Nueva carpeta",
    "noData": "No hay datos",
    "precise": "Preciso",
    "presencePenalty": "Penalización por Repetición",
    "presencePenaltyDescription": "Los valores positivos penalizan los nuevos tokens en función de si aparecen en el texto hasta el momento, lo que aumenta la probabilidad de que el modelo hable sobre nuevos temas. De forma predeterminada, es la configuración del proveedor de modelos.",
    "regenerateResponse": "Regenerar respuesta",
    "repeatPenalty": "Penalización por Repetición",
    "repeatPenaltyDescription": "Los valores positivos penalizan los nuevos tokens en función de su frecuencia actual en el texto hasta el momento. Disminuye la probabilidad del modelo de repetir la misma línea textualmente. También se conoce como «penalización por frecuencia». De forma predeterminada, es la configuración del proveedor de modelos.",
    "search": "Buscar",
    "seed": "Semilla",
    "seedDescription": "La semilla utilizada para generar la respuesta. La misma semilla generará siempre la misma respuesta.",
    "startTyping": "Empieza a escribir, escribe / para seleccionar una plantilla...",
    "stop": "Detener",
    "stopDescription": "Lista de tokens separadas por comas para detener la generación. La IA dejará de generar tokens una vez que encuentre alguna de estos tokens.",
    "stopGenerating": "Parar de generar",
    "temperature": "Temperatura",
    "temperatureDescription": "Los valores más altos harán que la salida sea más aleatoria, mientras que los valores más bajos la harán más centrada y determinista.",
    "topK": "Top K",
    "topKDescription": "La cantidad de tokens de vocabulario de mayor probabilidad que se deben conservar para filtrar las k-principales. Entre 1 e infinito. De forma predeterminada, es la configuración del proveedor de modelos.",
    "topP": "Top P",
    "topPDescription": "La probabilidad acumulada de los símbolos de mayor probabilidad de los parámetros que se utilizarán para el muestreo del núcleo, entre 0 y 1. De forma predeterminada, es la configuración del proveedor de modelos."
  },
  "clearConversations": "Borrar todas las conversaciones",
  "default": "Por defecto",
  "error": {
    "fetchingModels": "Error al buscar modelos.",
    "keyMissing": "Asegúrate de que {{vendor}} la clave esté en la parte inferior izquierda de la barra lateral.",
    "vendorIssue": "Si has completado este paso, {{vendor}} es posible que tengas problemas."
  },
  "loading": "Cargando…",
  "markdown": {
    "copied": "¡Copiado!",
    "copyCode": "Copiar Código",
    "enterFileName": "Ingresar nombre del archivo"
  },
  "model": "Modelo",
  "modelDescription": "El modelo utilizado para esta conversación",
  "models": "Modelos",
  "name": "Nombre",
  "newSystemPrompt": "Nuevo system prompt",
  "noData": "No hay datos",
  "prompt": "Mensaje",
  "promptbar": {
    "description": "Descripción",
    "name": "Nombre",
    "newFolder": "Nueva carpeta",
    "newMessageTemplate": "Nueva plantilla de mensajes",
    "prompt": "Mensaje",
    "promptContent": "Contenido de la plantilla. Se usa {{}} para indicar una variable. Por ejemplo: {{name}} es un {{adjective}} {{noun}}",
    "save": "Guardar"
  },
  "save": "Guardar",
  "saveSubmit": "Guardar y enviar",
  "search": "Buscar",
  "settings": "Ajustes",
  "sidebar": {
    "exportData": "Exportar datos",
    "importData": "Importar datos"
  },
  "submit": "Confirmar",
  "sureQ": "¿Estás seguro?",
  "systemPrompt": "System prompt",
  "systemPromptDescription": "El system prompt que se utilizará al enviar un mensaje"
}